## Introduction {.page_break_before}

Gene expression datasets are typically "wide", with more gene features than samples.
These feature-rich and sample-poor datasets present challenges in many aspects of machine learning, including overfitting, multicollinearity, and interpretation.
To facilitate the use of feature-rich gene expression data in machine learning models, feature selection and/or dimension reduction are commonly used to distill a more condensed data representation from the input space of all genes.
The idea is that many gene expression features are likely to be redundant or irrelevant to the prediction problem of interest, so selecting or transforming them can generate a more relevant set of genes or variables.

In cancer transcriptomics, this preference for small, parsimonious sets of genes manifests in the popularity of "gene signatures".
These are groups of genes whose expression levels are used to define cancer subtypes or to predict prognosis or therapeutic response [@doi:10.1038/nrg.2017.96; @doi:10.1016/j.ejca.2013.02.021].
Many studies specify the size of the signature in the paper's title or abstract, suggesting that the fewer genes in a gene signature, the better [@doi:10.1056/NEJMoa060096; @doi:10.1158/0008-5472.CAN-08-0436; @doi:10.1056/NEJMoa1602253].
Clinically, there are many reasons why a smaller gene signature could be better, including cost (the expression of fewer genes can be profiled using PCR or immunohistochemistry, whereas a large signature likely requires a targeted array or NGS analysis) and interpretability (it is easier to reason about the function and biological role of a smaller gene set than a large one).
However, there is also an underlying assumption that smaller gene signatures tend to be more robust: that for a new patient or in a new biological context, a smaller gene set is more likely to maintain its predictive performance than a larger one.



## Results {.page_break_before}

### Measuring generalization using open cancer genomics data

Figure 1: graphical explanation of experimental design

### Generalization across datasets

Figure 2: summary of TCGA -> CCLE and CCLE -> TCGA results, by gene

Figure 3: explanation of "best" vs. "smallest good", distribution plot, examples

### Generalization across cancer types

Figure 4: cancer type generalization distribution plot, examples, cancer type representation analysis (which cancer types are hardest to generalize to?)

### Extension to nonlinear models

Figure 5: neural network results for varying dropout/other regularization

supplement: MSI prediction results, LASSO penalty vs. feature count plots, individual per-gene performance plots, feature count binning results


## Discussion {.page_break_before}


## Methods {.page_break_before}

### Data download and preprocessing

### Cancer gene set construction

Vogelstein gene set

### Classifier setup and cross-validation design

LASSO logistic regression details
LASSO range selection

### "Best model" vs. "smallest good model" analysis details

Description of "smallest good" heuristic
Statistical testing?

### Open science/reproducibility stuff
